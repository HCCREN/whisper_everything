{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02fd5274-69be-4e3e-9bcc-931e36e3294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in sound_data/20240530_meeting.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Converted 20240530會議錄製.mp4 to sound_data/20240530_meeting.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def convert_mp4_to_wav(mp4_file_path, wav_file_path):\n",
    "    # Load the video file\n",
    "    video = VideoFileClip(mp4_file_path)\n",
    "    \n",
    "    # Extract the audio\n",
    "    audio = video.audio\n",
    "    \n",
    "    # Write the audio to a WAV file\n",
    "    audio.write_audiofile(wav_file_path, codec='pcm_s16le')\n",
    "\n",
    "# Example usage\n",
    "mp4_file_path = '20240530會議錄製.mp4'\n",
    "wav_file_path = 'sound_data/20240530_meeting.wav'\n",
    "convert_mp4_to_wav(mp4_file_path, wav_file_path)\n",
    "\n",
    "print(f\"Converted {mp4_file_path} to {wav_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc50cd2f-3d85-4bee-a830-f2d3d99bc8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing audio files: 100%|█████████████████████████████████████████████████████████| 1/1 [06:18<00:00, 378.56s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import whisper\n",
    "from tqdm import tqdm  # Import the tqdm library\n",
    "\n",
    "def transcribe_audio_files(folder_path, model, output_folder):\n",
    "    # List all the files in the folder that are WAV files\n",
    "    file_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and f.endswith('.wav')]\n",
    "\n",
    "    # Initialize the progress bar\n",
    "    pbar = tqdm(total=len(file_names), desc=\"Transcribing audio files\")\n",
    "\n",
    "    for file_name in file_names:\n",
    "        # Load audio\n",
    "        audio_path = os.path.join(folder_path, file_name)\n",
    "        audio = whisper.load_audio(audio_path)\n",
    "\n",
    "        # Transcribe audio\n",
    "        text = model.transcribe(audio)\n",
    "\n",
    "        # Create and save text file\n",
    "        output_text_path = os.path.join(output_folder, f\"{file_name.split('.')[0]}_transcription.txt\")\n",
    "        with open(output_text_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(text['text'])\n",
    "        \n",
    "        # Update the progress bar after each file is processed\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    pbar.close()\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the whisper model\n",
    "model_size = \"small\"  # Chosen for compatibility with the available GPU VRAM\n",
    "model = whisper.load_model(model_size).to(device)\n",
    "\n",
    "# Folder paths\n",
    "input_folder = 'sound_data'\n",
    "output_folder = 'transcriptions'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Transcribe and save text\n",
    "transcribe_audio_files(input_folder, model, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c1c9bb-a6a6-4aee-998d-d678b79cd00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='sound_data/second_half_audio.mp3'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Path to your MP3 file\n",
    "mp3_file_path = 'sound_data/科專0627_A1.mp3'\n",
    "\n",
    "# Load the MP3 file\n",
    "audio_segment = AudioSegment.from_file(mp3_file_path, format=\"mp3\")\n",
    "\n",
    "# Calculate the midpoint of the audio file\n",
    "midpoint = len(audio_segment) // 2\n",
    "\n",
    "# Split the audio into two halves\n",
    "first_half = audio_segment[:midpoint]\n",
    "second_half = audio_segment[midpoint:]\n",
    "\n",
    "# Path to save the first half of the audio as WAV\n",
    "first_half_wav_path = 'sound_data/first_half_audio.mp3'\n",
    "\n",
    "# Path to save the second half of the audio as WAV\n",
    "second_half_wav_path = 'sound_data/second_half_audio.mp3'\n",
    "\n",
    "# Export the first half to a WAV file\n",
    "first_half.export(first_half_wav_path, format=\"mp3\")\n",
    "\n",
    "# Export the second half to a WAV file\n",
    "second_half.export(second_half_wav_path, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb39ee-b9f9-433b-bca5-dcc99dbaf288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
